

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lectura 7-2: Predictores categóricos e interacciones &#8212; MEL 202302</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Week_7/7-2-Categorical_variables';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Lectura 7-1: Regresión Lineal Múltiple" href="7-1-Multiple_linear_regresion.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../Syllabus.html">
  
  
  
  
  
    <p class="title logo__title">MEL 202302</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../Syllabus.html">
                    Syllabus
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_1/1-0-Schedule_week_1.html">Semana 1. Introducción al análisis estadístico</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Week_1/1-1-Introduction_pensamiento_stat.html">Lectura 1-1: Introducción al Pensamiento estadístico</a></li>




<li class="toctree-l1"><a class="reference internal" href="../Week_1/1-2-Estad%C3%ADstica_descriptiva.html">Lectura 1-2:  Estadística Descriptiva</a></li>








<li class="toctree-l1"><a class="reference internal" href="../Week_1/1-3-Visualizations.html">Lectura 1-3: Visualización de datos con Python</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_2/2-0-Schedule_week_2.html">Semana 2. Probabilidad y distribuciones Probabilidad y Distribuciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Week_2/2-1-Prob.html">Lectura 2-1: Probabilidad y estadística</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_3/3-1-Inference.html">Lectura 3-1: Inferencia estadística</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Week_3/3-2-Hypothesis.html">Lectura 3-2: Pruebas de Hipotesis</a></li>







<li class="toctree-l1"><a class="reference internal" href="../Week_3/3-3-Hypothesis_2.html">Lectura 3-3: Pruebas de Hipotesis 2.</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_4/4-1%20Correlaciones.html">Lectura 4-1: Correlaciones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Week_4/4-2-Simple_linear_regression.html">Lectura 4-2: Regresión lineal simple</a></li>




<li class="toctree-l1"><a class="reference internal" href="../Week_4/4-3-SLR_supuestos.html">Lectura 4-3: Supuestos de la regresión lineal simple</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_5/5-2-Hypothesis_Confidence.html">Lectura 5-1: Inferencia en RLS</a></li>









</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Semana 7</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="7-1-Multiple_linear_regresion.html">Lectura 7-1: Regresión Lineal Múltiple</a></li>


<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lectura 7-2: Predictores categóricos e interacciones</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/tabarespozos/MEL_202302/blob/MEL_202302/Week_7/7-2-Categorical_variables.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tabarespozos/MEL_202302" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tabarespozos/MEL_202302/issues/new?title=Issue%20on%20page%20%2FWeek_7/7-2-Categorical_variables.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Week_7/7-2-Categorical_variables.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lectura 7-2: Predictores categóricos e interacciones</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Lectura 7-2: Predictores categóricos e interacciones</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-ficticias">Variables ficticias</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#interacciones">Interacciones</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-categoricas">Variables categóricas</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factores-con-mas-de-dos-niveles">Factores con más de dos niveles</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#parametrizacion">Parametrización</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-modelos-mas-amplios">Creación de modelos más amplios</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="lectura-7-2-predictores-categoricos-e-interacciones">
<h1>Lectura 7-2: Predictores categóricos e interacciones<a class="headerlink" href="#lectura-7-2-predictores-categoricos-e-interacciones" title="Permalink to this heading">#</a></h1>
<p>Hasta ahora, en cada uno de nuestros análisis, sólo hemos utilizado variables numéricas como predictores. También hemos utilizado únicamente <em>modelos aditivos</em>, lo que significa que el efecto que cualquier predictor tenía sobre la respuesta no dependía de los otros predictores. En este capítulo, eliminaremos estas dos restricciones. Ajustaremos modelos con predictores categóricos y utilizaremos modelos que permiten que los predictores <em>interactúen</em>. Las matemáticas de la regresión múltiple permanecerán en gran medida inalteradas, sin embargo, prestaremos mucha atención a la interpretación, así como a algunas diferencias en el uso en <code class="docutils literal notranslate"><span class="pre">python</span></code>.</p>
</section>
<section id="variables-ficticias">
<h1>Variables ficticias<a class="headerlink" href="#variables-ficticias" title="Permalink to this heading">#</a></h1>
<p>En este capítulo, utilizaremos brevemente el conjunto de datos incorporado <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> antes de volver a nuestro conjunto de datos <code class="docutils literal notranslate"><span class="pre">autompg</span></code> que usamos en la lectura anterior. El conjunto de datos <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> es algo más pequeño, por lo que echaremos un vistazo rápidamente a todo el conjunto de datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.predstd</span> <span class="kn">import</span> <span class="n">wls_prediction_std</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="c1"># Please note that you need to install openpyxl to read .xlsx files</span>

<span class="c1"># Read the .xlsx file</span>
<span class="n">mtcars</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;../data/mtcars.xlsx&#39;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;openpyxl&#39;</span><span class="p">)</span>

<span class="c1"># Display the dataframe</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mtcars</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb
0   21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4
1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4
2   22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1
3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1
4   18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2
5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1
6   14.3    8  360.0  245  3.21  3.570  15.84   0   0     3     4
7   24.4    4  146.7   62  3.69  3.190  20.00   1   0     4     2
8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2
9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4
10  17.8    6  167.6  123  3.92  3.440  18.90   1   0     4     4
11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3
12  17.3    8  275.8  180  3.07  3.730  17.60   0   0     3     3
13  15.2    8  275.8  180  3.07  3.780  18.00   0   0     3     3
14  10.4    8  472.0  205  2.93  5.250  17.98   0   0     3     4
15  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3     4
16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4
17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1
18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2
19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1
20  21.5    4  120.1   97  3.70  2.465  20.01   1   0     3     1
21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2
22  15.2    8  304.0  150  3.15  3.435  17.30   0   0     3     2
23  13.3    8  350.0  245  3.73  3.840  15.41   0   0     3     4
24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2
25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1
26  26.0    4  120.3   91  4.43  2.140  16.70   0   1     5     2
27  30.4    4   95.1  113  3.77  1.513  16.90   1   1     5     2
28  15.8    8  351.0  264  4.22  3.170  14.50   0   1     5     4
29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6
30  15.0    8  301.0  335  3.54  3.570  14.60   0   1     5     8
31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2
</pre></div>
</div>
</div>
</div>
<p>Nos interesarán tres de las variables: <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, <code class="docutils literal notranslate"><span class="pre">hp</span></code> y <code class="docutils literal notranslate"><span class="pre">am</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mpg</span></code>: eficiencia del combustible, en millas por galón.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hp</span></code>: caballos de fuerza, en libras-pie por segundo.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">am</span></code>: transmisión. Automática o manual.</p></li>
</ul>
<p>Como hacemos a menudo, vamos a empezar por trazar los datos. Estamos interesados en <code class="docutils literal notranslate"><span class="pre">mpg</span></code> como variable de respuesta, y <code class="docutils literal notranslate"><span class="pre">hp</span></code> como predictor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
<span class="c1">#include line of best fit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">))(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">])),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;hp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e91675d06a7acf6e2b85fa29dec10c89435b97c57e89d7353eb1820067d7c227.png" src="../_images/e91675d06a7acf6e2b85fa29dec10c89435b97c57e89d7353eb1820067d7c227.png" />
</div>
</div>
<p>Como también nos interesa el tipo de transmisión, también podríamos etiquetar los puntos en consecuencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Colors and markers based on &#39;am&#39;</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">markers</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;o&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>

<span class="c1"># Scatter plot</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">]):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">subset</span><span class="o">.</span><span class="n">index</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Automatic&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;Manual&#39;</span><span class="p">)</span>

<span class="c1"># Line of best fit</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>


<span class="c1"># Additional configurations</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;hp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;HP vs MPG with Transmission Type differentiation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2f0294150ee0c1e6d66769d1bb744739ed2581465ddd5453623867b1a5edb759.png" src="../_images/2f0294150ee0c1e6d66769d1bb744739ed2581465ddd5453623867b1a5edb759.png" />
</div>
</div>
<p>Ahora ajustamos el modelo SLR</p>
<div class="math notranslate nohighlight">
\[ Y = \beta_0 + \beta_1 x_1 + \epsilon, \]</div>
<p>donde <span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code> y <span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">hp</span></code>. Por brevedad, suprimimos el índice <span class="math notranslate nohighlight">\(i\)</span> para las observaciones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linear regression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[[</span><span class="s1">&#39;hp&#39;</span><span class="p">]]))</span>
<span class="n">mpg_hp_slr</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>A continuación, volvemos a representar los datos y añadimos la línea ajustada al gráfico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Colors and markers based on &#39;am&#39;</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">markers</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;o&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>

<span class="c1"># Scatter plot</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">]):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">subset</span><span class="o">.</span><span class="n">index</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Automatic&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;Manual&#39;</span><span class="p">)</span>

<span class="c1"># Line of best fit</span>
<span class="n">X_for_prediction</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[[</span><span class="s1">&#39;hp&#39;</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">mpg_hp_slr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_for_prediction</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="c1"># Additional configurations</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;hp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;HP vs MPG with Transmission Type differentiation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/6f7a34a8393e45aab0484fd445e524a5035a3506624c6743ce5e5dec4f104af1.png" src="../_images/6f7a34a8393e45aab0484fd445e524a5035a3506624c6743ce5e5dec4f104af1.png" />
</div>
</div>
<p>Deberíamos notar un patrón aquí. Las observaciones manuales azules se sitúan en gran medida por encima de la línea, mientras que las observaciones automáticas rojas se sitúan en su mayoría por debajo de la línea. Esto significa que nuestro modelo subestima la eficiencia de combustible de las transmisiones manuales, y sobreestima la eficiencia de combustible de las transmisiones automáticas. Para corregir esto, vamos a añadir un predictor a nuestro modelo, a saber, <code class="docutils literal notranslate"><span class="pre">am</span></code> como <span class="math notranslate nohighlight">\(x_2\)</span>.</p>
<p>Nuestro nuevo modelo es</p>
<div class="math notranslate nohighlight">
\[ Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon, \]</div>
<p>donde <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(Y\)</span> siguen siendo los mismos, pero ahora</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
x_2 =
  \begin{cases}
   1 &amp; \text{manual transmission} \\
   0       &amp; \text{automatic transmission}
  \end{cases}.
\end{split}\]</div>
<p>En este caso, llamamos a <span class="math notranslate nohighlight">\(x_2\)</span> una <strong>variable dummy</strong>. Una variable dummy (o ficticia) tiene un nombre un tanto desafortunado, ya que no es en absoluto “tonta”. De hecho, es algo inteligente. Una variable de este tipo es una variable numérica que se utiliza en un análisis de regresión para “codificar” una variable categórica binaria. Veamos cómo funciona.</p>
<ul class="simple">
<li><p>En primer lugar, observe que <code class="docutils literal notranslate"><span class="pre">am</span></code> ya es una variable ficticia, puesto que utiliza los valores <code class="docutils literal notranslate"><span class="pre">0</span></code> y <code class="docutils literal notranslate"><span class="pre">1</span></code> para representar las transmisiones automática y manual. A menudo, una variable como <code class="docutils literal notranslate"><span class="pre">am</span></code> almacenaría los valores de carácter <code class="docutils literal notranslate"><span class="pre">auto</span></code> y <code class="docutils literal notranslate"><span class="pre">man</span></code> y tendríamos que convertirlos a <code class="docutils literal notranslate"><span class="pre">0</span></code> y <code class="docutils literal notranslate"><span class="pre">1</span></code> o, como veremos más adelante, <code class="docutils literal notranslate"><span class="pre">Python</span></code> se encargará de crear variables ficticias por nosotros.</p></li>
</ul>
<p>Así que, para ajustar el modelo anterior, lo hacemos como cualquier otro modelo de regresión múltiple que hayamos visto antes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># Regression</span>
<span class="n">mpg_hp_add</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ hp + am&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.782
Model:                            OLS   Adj. R-squared:                  0.767
Method:                 Least Squares   F-statistic:                     52.02
Date:                Tue, 19 Sep 2023   Prob (F-statistic):           2.55e-10
Time:                        21:35:40   Log-Likelihood:                -78.003
No. Observations:                  32   AIC:                             162.0
Df Residuals:                      29   BIC:                             166.4
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     26.5849      1.425     18.655      0.000      23.670      29.500
hp            -0.0589      0.008     -7.495      0.000      -0.075      -0.043
am             5.2771      1.080      4.888      0.000       3.069       7.485
==============================================================================
Omnibus:                        0.879   Durbin-Watson:                   1.457
Prob(Omnibus):                  0.644   Jarque-Bera (JB):                0.805
Skew:                           0.117   Prob(JB):                        0.669
Kurtosis:                       2.259   Cond. No.                         495.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<p>Comprobando brevemente la salida, vemos que <code class="docutils literal notranslate"><span class="pre">Python</span></code> ha estimado los tres parámetros <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    26.584914
hp           -0.058888
am            5.277085
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Dado que <span class="math notranslate nohighlight">\(x_2\)</span> sólo puede tomar valores <code class="docutils literal notranslate"><span class="pre">0</span></code> y <code class="docutils literal notranslate"><span class="pre">1</span></code>, podemos escribir efectivamente dos modelos diferentes, uno para transmisiones manuales y otro para transmisiones automáticas.</p>
<p>Para transmisiones automáticas, es decir <span class="math notranslate nohighlight">\(x_2 = 0\)</span>, tenemos,</p>
<div class="math notranslate nohighlight">
\[ Y = \beta_0 + \beta_1 x_1 + \epsilon. \]</div>
<p>Entonces para transmisiones manuales, es decir <span class="math notranslate nohighlight">\(x_2 = 1\)</span>, tenemos,</p>
<div class="math notranslate nohighlight">
\[ Y = (\beta_0 + \beta_2) + \beta_1 x_1 + \epsilon. \]</div>
<p>Observe que estos modelos comparten la misma pendiente, <span class="math notranslate nohighlight">\(\beta_1\)</span>, pero tienen diferentes interceptos, que difieren en <span class="math notranslate nohighlight">\(\beta_2\)</span>. Así que el cambio en <code class="docutils literal notranslate"><span class="pre">mpg</span></code> es el mismo para ambos modelos, pero en promedio <code class="docutils literal notranslate"><span class="pre">mpg</span></code> difiere en <span class="math notranslate nohighlight">\(\beta_2\)</span> entre los dos tipos de transmisión.</p>
<p>Ahora vamos a calcular la pendiente estimada y el intercepto de estos dos modelos para que podamos añadirlos a un gráfico. Tenga en cuenta que:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span> = <code class="docutils literal notranslate"><span class="pre">26.584914</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> = <code class="docutils literal notranslate"> <span class="pre">-0.05888</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_2\)</span> = <code class="docutils literal notranslate"> <span class="pre">5.277085</span></code></p></li>
</ul>
<p>A continuación, podemos combinarlos para calcular la pendiente y los interceptos estimados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract coefficients</span>
<span class="n">int_auto</span> <span class="o">=</span> <span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span>
<span class="n">int_manu</span> <span class="o">=</span> <span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">int_auto</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">int_manu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>26.584913747970575
31.861999056149198
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slope_auto</span> <span class="o">=</span> <span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]</span>
<span class="n">slope_manu</span> <span class="o">=</span> <span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">slope_auto</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">slope_manu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.05888780335351099
-0.05888780335351099
</pre></div>
</div>
</div>
</div>
<p>Al volver a representar los datos, utilizamos estas pendientes e interceptos para añadir los “dos” modelos ajustados al gráfico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Colors and markers based on &#39;am&#39;</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">markers</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;o&#39;</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>

<span class="c1"># Scatter plot</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">]):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">mtcars</span><span class="p">[</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;am&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">subset</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">subset</span><span class="o">.</span><span class="n">index</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Automatic&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;Manual&#39;</span><span class="p">)</span>

<span class="c1"># Add regression lines</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">mtcars</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">int_auto</span> <span class="o">+</span> <span class="n">slope_auto</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">int_manu</span> <span class="o">+</span> <span class="n">slope_manu</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Additional configurations</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;hp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;HP vs MPG with Transmission Type differentiation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/85672dc9815aa5432792485e3222ff118cc2fc99535b53d35f463b50d9562dfd.png" src="../_images/85672dc9815aa5432792485e3222ff118cc2fc99535b53d35f463b50d9562dfd.png" />
</div>
</div>
<p>Observamos enseguida que los puntos ya no son sistemáticamente incorrectos. Las observaciones rojas, manuales, varían en torno a la línea roja sin ningún patrón particular, sin subestimar las observaciones como antes. Los puntos negros, automáticos, varían en torno a la línea negra, también sin un patrón evidente.</p>
<p>Dicen que una imagen vale más que mil palabras, pero como estadístico, a veces una imagen vale más que todo un análisis. La imagen anterior hace claramente obvio que <span class="math notranslate nohighlight">\(\beta_2\)</span> es significativo, pero vamos a verificar matemáticamente. Esencialmente nos gustaría probar:</p>
<div class="math notranslate nohighlight">
\[
H_0: \beta_2 = 0 \quad \text{vs} \quad H_1: \beta_2 \neq 0.
\]</div>
<p>Esto no es nada nuevo. De nuevo, las matemáticas son las mismas que las de los análisis de regresión múltiple que hemos visto antes. Podríamos realizar aquí una prueba <span class="math notranslate nohighlight">\(t\)</span> o <span class="math notranslate nohighlight">\(F\)</span>. La única diferencia es un ligero cambio en la interpretación. Podríamos pensar en esto como una prueba de un modelo con una sola línea (<span class="math notranslate nohighlight">\(H_0\)</span>) contra un modelo que permite dos líneas (<span class="math notranslate nohighlight">\(H_1\)</span>).</p>
<p>Para obtener el estadístico de prueba y el valor p para la prueba <span class="math notranslate nohighlight">\(t\)</span>, utilizaríamos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract the &#39;am&#39; coefficient details from the summary</span>
<span class="n">summary_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">columns</span><span class="o">=</span><span class="n">mpg_hp_add</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">am_coeff</span> <span class="o">=</span> <span class="n">summary_df</span><span class="p">[</span><span class="n">summary_df</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;am&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">am_coeff</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>             coef    std err          t   P&gt;|t|     [0.025     0.975]
2  am      5.2771      1.080      4.888   0.000      3.069      7.485
</pre></div>
</div>
</div>
</div>
<p>Para hacer lo mismo con la prueba <span class="math notranslate nohighlight">\(F\)</span>, utilizaríamos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform ANOVA test between the two models</span>
<span class="n">anova_results</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">mpg_hp_slr</span><span class="p">,</span> <span class="n">mpg_hp_add</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid         ssr  df_diff     ss_diff          F    Pr(&gt;F)
0      30.0  447.674314      0.0         NaN        NaN       NaN
1      29.0  245.439288      1.0  202.235025  23.895179  0.000035
</pre></div>
</div>
</div>
</div>
<p>Observe que, en efecto, se trata de la misma prueba, ya que los valores p son exactamente iguales. (Y el estadístico de prueba <span class="math notranslate nohighlight">\(F\)</span> es el estadístico de prueba <span class="math notranslate nohighlight">\(t\)</span> al cuadrado).</p>
<p>Recapitulando algunas interpretaciones:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_0 = 26.58\)</span> es el consumo medio estimado para un coche con transmisión automática y <strong>0</strong> <code class="docutils literal notranslate"><span class="pre">hp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_0 + \hat{\beta}_2 = 31.86\)</span>  es la media estimada de “mpg” de un coche con transmisión manual
y <strong>0</strong> <code class="docutils literal notranslate"><span class="pre">hp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_2 = 5.27\)</span> es la <strong>diferencia</strong> estimada en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> de los carros con transmisión manual respecto a los de transmisión automática, para <strong>cualquier</strong> <code class="docutils literal notranslate"><span class="pre">hp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_1 = -0.058\)</span> es el cambio estimado en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de un <code class="docutils literal notranslate"><span class="pre">hp</span></code>, para <strong>cualquiera</strong> de los tipos de transmisión.</p></li>
</ul>
<p>Debemos prestar especial atención a los dos últimos. En el modelo,</p>
<div class="math notranslate nohighlight">
\[
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon,
\]</div>
<p>Vemos que <span class="math notranslate nohighlight">\(\beta_1\)</span> es el cambio medio en <span class="math notranslate nohighlight">\(Y\)</span> para un aumento en <span class="math notranslate nohighlight">\(x_1\)</span>, <em>sin importar</em> el valor de <span class="math notranslate nohighlight">\(x_2\)</span>. Además, <span class="math notranslate nohighlight">\(\beta_2\)</span> es siempre la diferencia en la media de <span class="math notranslate nohighlight">\(Y\)</span> para <em>cualquier</em> valor de <span class="math notranslate nohighlight">\(x_1\)</span>. Estas son dos restricciones que no siempre vamos a querer, por lo que necesitamos una manera de especificar un modelo más flexible.</p>
<p>Aquí nos limitamos a un único predictor numérico <span class="math notranslate nohighlight">\(x_1\)</span> y una variable ficticia <span class="math notranslate nohighlight">\(x_2\)</span>. Sin embargo, el concepto de variable ficticia puede utilizarse con modelos de regresión múltiple más amplios. Aquí sólo utilizamos un único predictor numérico para facilitar la visualización, ya que podemos pensar en la interpretación de “dos líneas”. Pero en general, podemos pensar en una variable ficticia como la creación de “dos modelos”, uno para cada categoría de una variable categórica binaria.</p>
</section>
<section id="interacciones">
<h1>Interacciones<a class="headerlink" href="#interacciones" title="Permalink to this heading">#</a></h1>
<p>Para eliminar la restricción de la “misma pendiente”, hablaremos ahora de <strong>interacción</strong>. Para ilustrar este concepto, volveremos al conjunto de datos <code class="docutils literal notranslate"><span class="pre">autompg</span></code> que creamos en una anterior lectura,  con algunas modificaciones más.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Read data frame from the web</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data&quot;</span>
<span class="n">autompg</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">comment</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">quotechar</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">na_values</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;?&quot;</span><span class="p">])</span>

<span class="c1"># Assign headers to the dataframe</span>
<span class="n">autompg</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;mpg&quot;</span><span class="p">,</span> <span class="s2">&quot;cyl&quot;</span><span class="p">,</span> <span class="s2">&quot;disp&quot;</span><span class="p">,</span> <span class="s2">&quot;hp&quot;</span><span class="p">,</span> <span class="s2">&quot;wt&quot;</span><span class="p">,</span> <span class="s2">&quot;acc&quot;</span><span class="p">,</span> <span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="s2">&quot;origin&quot;</span><span class="p">,</span> <span class="s2">&quot;name&quot;</span><span class="p">]</span>

<span class="c1"># Remove rows with missing &#39;hp&#39; data</span>
<span class="n">autompg</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>

<span class="c1"># Remove &#39;plymouth reliant&#39;</span>
<span class="n">autompg</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;plymouth reliant&quot;</span><span class="p">]</span>

<span class="c1"># Create row names based on the engine, year, and name</span>
<span class="n">autompg</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; cylinder &quot;</span> <span class="o">+</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>

<span class="c1"># Drop the &#39;name&#39; column</span>
<span class="n">autompg</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Convert horsepower from object to numeric</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;hp&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

<span class="c1"># Create a dummy variable for foreign vs. domestic cars. Domestic = 1.</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Remove 3 and 5 cylinder cars</span>
<span class="n">autompg</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="o">~</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])]</span>

<span class="c1"># Change &#39;cyl&#39; to a category variable</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

<span class="c1"># Display the structure (similar to str in R)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 383 entries, 8 cylinder 70 chevrolet chevelle malibu to 4 cylinder 82 chevy s-10
Data columns (total 9 columns):
 #   Column    Non-Null Count  Dtype   
---  ------    --------------  -----   
 0   mpg       383 non-null    float64 
 1   cyl       383 non-null    category
 2   disp      383 non-null    float64 
 3   hp        383 non-null    float64 
 4   wt        383 non-null    float64 
 5   acc       383 non-null    float64 
 6   year      383 non-null    int64   
 7   origin    383 non-null    int64   
 8   domestic  383 non-null    int32   
dtypes: category(1), float64(5), int32(1), int64(2)
memory usage: 25.9+ KB
None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">autompg</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cyl</th>
      <th>disp</th>
      <th>hp</th>
      <th>wt</th>
      <th>acc</th>
      <th>year</th>
      <th>origin</th>
      <th>domestic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>8 cylinder 70 chevrolet chevelle malibu</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130.0</td>
      <td>3504.0</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8 cylinder 70 buick skylark 320</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165.0</td>
      <td>3693.0</td>
      <td>11.5</td>
      <td>70</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8 cylinder 70 plymouth satellite</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150.0</td>
      <td>3436.0</td>
      <td>11.0</td>
      <td>70</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8 cylinder 70 amc rebel sst</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150.0</td>
      <td>3433.0</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8 cylinder 70 ford torino</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140.0</td>
      <td>3449.0</td>
      <td>10.5</td>
      <td>70</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Hemos eliminado los carros con <code class="docutils literal notranslate"><span class="pre">3</span></code> y <code class="docutils literal notranslate"><span class="pre">5</span></code> cilindros, así como creado una nueva variable <code class="docutils literal notranslate"><span class="pre">domestic</span></code> que indica si un coche fue fabricado o no en Estados Unidos. La eliminación de los cilindros <code class="docutils literal notranslate"><span class="pre">3</span></code> y <code class="docutils literal notranslate"><span class="pre">5</span></code> es simplemente para facilitar la demostración más adelante en la lectura y no se haría en la práctica. La nueva variable <code class="docutils literal notranslate"><span class="pre">domestic</span></code> toma el valor <code class="docutils literal notranslate"><span class="pre">1</span></code> si el coche fue construido en Estados Unidos, y <code class="docutils literal notranslate"><span class="pre">0</span></code> en caso contrario, a lo que nos referiremos como “extranjero”. (También hemos convertido <code class="docutils literal notranslate"><span class="pre">cyl</span></code> y <code class="docutils literal notranslate"><span class="pre">origin</span></code> en variables factoriales, de las que hablaremos más adelante.</p>
<p>Ahora nos ocuparemos de tres variables: <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, <code class="docutils literal notranslate"><span class="pre">disp</span></code> y <code class="docutils literal notranslate"><span class="pre">doméstico</span></code>. Utilizaremos <code class="docutils literal notranslate"><span class="pre">mpg</span></code> como respuesta. Podemos ajustar un modelo,</p>
<div class="math notranslate nohighlight">
\[ 
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon,
\]</div>
<p>donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, la eficiencia del combustible en millas por galón,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>,la cilindrada en pulgadas cúbicas,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> es <code class="docutils literal notranslate"><span class="pre">domestic</span></code> como se ha descrito anteriormente, que es una variable ficticia.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
x_2 =
  \begin{cases}
   1 &amp; \text{Domestic} \\
   0 &amp; \text{Foreign}
  \end{cases}
\end{split}\]</div>
<p>Ajustaremos este modelo, extraeremos la pendiente y la intersección de las “dos rectas”, representaremos los datos y sumaremos las rectas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming &#39;autompg&#39; dataframe is already loaded as in the previous conversion.</span>

<span class="c1"># Fit linear regression model</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[[</span><span class="s1">&#39;disp&#39;</span><span class="p">,</span> <span class="s1">&#39;domestic&#39;</span><span class="p">]]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Add a constant for the intercept</span>
<span class="n">mpg_disp_add</span><span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Get coefficients</span>
<span class="n">int_for</span> <span class="o">=</span> <span class="n">mpg_disp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;const&#39;</span><span class="p">]</span>
<span class="n">int_dom</span> <span class="o">=</span> <span class="n">mpg_disp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;const&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">mpg_disp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span>
<span class="n">slope_for</span> <span class="o">=</span> <span class="n">mpg_disp_add</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span>
<span class="n">slope_dom</span> <span class="o">=</span> <span class="n">mpg_disp_add</span> <span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span>

<span class="c1"># Plotting</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">],</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;disp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>

<span class="c1"># Adding regression lines</span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">int_for</span> <span class="o">+</span> <span class="n">slope_for</span> <span class="o">*</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Foreign cars&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">int_dom</span> <span class="o">+</span> <span class="n">slope_dom</span> <span class="o">*</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Domestic cars&#39;</span><span class="p">)</span>

<span class="c1"># Adding legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ea3f7f1588c8722d257acd4d4ce4d9f517a13c28eb92b409f346fb19e46b6cf0.png" src="../_images/ea3f7f1588c8722d257acd4d4ce4d9f517a13c28eb92b409f346fb19e46b6cf0.png" />
</div>
</div>
<p>Se trata de un modelo que tiene en cuenta dos líneas <em>paralelas</em>, lo que significa que los <code class="docutils literal notranslate"><span class="pre">mpg</span></code> pueden ser diferentes de media entre carros extranjeros y nacionales de la misma cilindrada, pero el cambio en los <code class="docutils literal notranslate"><span class="pre">mpg</span></code> medios para un aumento de la cilindrada es el mismo para ambos. Podemos ver que este modelo no funciona muy bien aquí. La línea roja se ajusta bastante bien a los puntos amarillos, pero la línea azul no lo hace muy bien para los puntos violeta, debería tener claramente una pendiente más negativa. Esencialmente, nos gustaría un modelo que permita dos pendientes diferentes.</p>
<p>Consideremos el siguiente modelo,</p>
<div class="math notranslate nohighlight">
\[ 
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
\]</div>
<p>donde <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, y <span class="math notranslate nohighlight">\(Y\)</span> son los mismos que antes, pero hemos añadido un nuevo término de <strong>interacción</strong> <span class="math notranslate nohighlight">\(x_1 x_2\)</span> que multiplica <span class="math notranslate nohighlight">\(x_1\)</span> y <span class="math notranslate nohighlight">\(x_2\)</span>, por lo que también tenemos un parámetro <span class="math notranslate nohighlight">\(\beta\)</span> adicional <span class="math notranslate nohighlight">\(\beta_3.\)</span></p>
<p>Este modelo crea esencialmente dos pendientes y dos interceptos, siendo <span class="math notranslate nohighlight">\(\beta_2\)</span> la diferencia en interceptos y <span class="math notranslate nohighlight">\(\beta_3\)</span> la diferencia en pendientes. Para ver esto, vamos a desglosar el modelo en los dos “submodelos” para los carros extranjeros y nacionales.</p>
<p>Para los carros extranjeros, es decir <span class="math notranslate nohighlight">\(x_2 = 0\)</span>, tenemos</p>
<div class="math notranslate nohighlight">
\[
Y = \beta_0 + \beta_1 x_1 + \epsilon.
\]</div>
<p>Para los carros nacionales, es decir <span class="math notranslate nohighlight">\(x_2 = 1\)</span>, tenemos</p>
<div class="math notranslate nohighlight">
\[
Y = (\beta_0 + \beta_2) + (\beta_1 + \beta_3) x_1 + \epsilon.
\]</div>
<p>Estos dos modelos tienen pendientes e interceptos diferentes.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> es la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> de un coche extranjero con <strong>0</strong> <code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1\)</span> es el cambio en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de un <code class="docutils literal notranslate"><span class="pre">disp</span></code>, para carros <strong>extranjeros</strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0 + \beta_2\)</span> es la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> de un coche nacional con
<strong>0</strong> <code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_1 + \beta_3\)</span> es el cambio en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de un <code class="docutils literal notranslate"><span class="pre">disp</span></code>, para carros <strong>domésticos</strong>.</p></li>
</ul>
<p>¿Cómo ajustamos este modelo en <code class="docutils literal notranslate"><span class="pre">Python</span></code>? Hay varias formas de hacerlo.</p>
<p>Un método sería simplemente crear una nueva variable, y luego ajustar un modelo como cualquier otro.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create interaction term</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;x3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Sólo debe hacerlo como último recurso. Preferimos no tener que modificar nuestros datos simplemente para ajustar un modelo. En su lugar, podemos decirle a <code class="docutils literal notranslate"><span class="pre">Python</span></code> que nos gustaría utilizar los datos existentes con un término de interacción.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Interaction term (though we don&#39;t really need to create it manually with the formula API)</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;x3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span>

<span class="c1"># Fit linear regression models</span>
<span class="n">model_int</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp + domestic + x3&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Un método alternativo, que se ajustará exactamente al mismo modelo que el anterior, sería utilizar el operador <code class="docutils literal notranslate"><span class="pre">*</span></code>. Este método crea automáticamente el término de interacción, así como cualquier “término de orden inferior”, que en este caso son los términos de primer orden para <code class="docutils literal notranslate"><span class="pre">disp</span></code> y <code class="docutils literal notranslate"><span class="pre">domestic</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_int2</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp * domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>  <span class="c1"># Equivalent to the previous model</span>
</pre></div>
</div>
</div>
</div>
<p>Podemos comprobar rápidamente que hacen lo mismo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_int2</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    46.054842
disp         -0.156924
domestic    -12.575471
x3            0.102518
dtype: float64
Intercept        46.054842
disp             -0.156924
domestic        -12.575471
disp:domestic     0.102518
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Vemos que tanto las variables como las estimaciones de sus coeficientes son efectivamente las mismas para ambos modelos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print summary for model_int</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_int2</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.701
Model:                            OLS   Adj. R-squared:                  0.699
Method:                 Least Squares   F-statistic:                     296.3
Date:                Tue, 19 Sep 2023   Prob (F-statistic):           5.41e-99
Time:                        21:35:41   Log-Likelihood:                -1100.8
No. Observations:                 383   AIC:                             2210.
Df Residuals:                     379   BIC:                             2225.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept        46.0548      1.806     25.504      0.000      42.504      49.606
disp             -0.1569      0.017     -9.407      0.000      -0.190      -0.124
domestic        -12.5755      1.956     -6.428      0.000     -16.422      -8.729
disp:domestic     0.1025      0.017      6.060      0.000       0.069       0.136
==============================================================================
Omnibus:                       52.188   Durbin-Watson:                   0.865
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               77.495
Skew:                           0.879   Prob(JB):                     1.49e-17
Kurtosis:                       4.328   Cond. No.                     3.61e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.61e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Vemos que utilizando <code class="docutils literal notranslate"><span class="pre">summary()</span></code> se obtienen los resultados habituales de un modelo de regresión múltiple. Prestamos mucha atención a la fila para <code class="docutils literal notranslate"><span class="pre">disp:domestic</span></code> que prueba,</p>
<div class="math notranslate nohighlight">
\[
H_0: \beta_3 = 0.
\]</div>
<p>En este caso, la prueba de <span class="math notranslate nohighlight">\(\beta_3 = 0\)</span> es la prueba de dos líneas con pendientes paralelas frente a dos líneas con pendientes posiblemente diferentes. La línea <code class="docutils literal notranslate"><span class="pre">disp:domestic</span></code> en la salida <code class="docutils literal notranslate"><span class="pre">summary()</span></code> utiliza una prueba <span class="math notranslate nohighlight">\(t\)</span> para realizar la prueba.</p>
<p>También podríamos utilizar una prueba ANOVA <span class="math notranslate nohighlight">\(F\)</span>. El modelo aditivo sin interacción es nuestro modelo nulo, y el modelo de interacción es el alternativo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.stats.anova</span> <span class="kn">import</span> <span class="n">anova_lm</span>
<span class="n">anova_results</span> <span class="o">=</span> <span class="n">anova_lm</span><span class="p">(</span><span class="n">mpg_disp_add</span> <span class="p">,</span> <span class="n">model_int2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid          ssr  df_diff     ss_diff          F        Pr(&gt;F)
0     380.0  7713.981816      0.0         NaN        NaN           NaN
1     379.0  7032.625063      1.0  681.356754  36.719462  3.293721e-09
</pre></div>
</div>
</div>
</div>
<p>De nuevo vemos que esta prueba tiene el mismo valor p que la prueba <span class="math notranslate nohighlight">\(t\)</span>. También el valor p es extremadamente bajo, por lo que entre los dos, elegimos el modelo de interacción.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># 1. Fit the interaction model and print the parameters</span>
<span class="n">model_int</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp * domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>  <span class="c1"># This will give you the names of the coefficients</span>

<span class="c1"># Now, manually check the printed coefficients&#39; names, especially those for the `domestic` dummy variable and the interaction term.</span>

<span class="c1"># Assuming the coefficient names are &#39;domestic&#39;, &#39;disp:domestic&#39; (but please adjust if they&#39;re different)</span>
<span class="n">int_for</span> <span class="o">=</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span>
<span class="n">int_dom</span> <span class="o">=</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span>
<span class="n">slope_for</span> <span class="o">=</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span>
<span class="n">slope_dom</span> <span class="o">=</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">model_int</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp:domestic&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept        46.054842
disp             -0.156924
domestic        -12.575471
disp:domestic     0.102518
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Aquí calculamos de nuevo la pendiente y los interceptos de las dos rectas para utilizarlos en el trazado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">],</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;mpg&#39;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;disp&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;mpg&#39;</span><span class="p">)</span>

<span class="c1"># Adding regression lines</span>
<span class="n">x_vals</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">int_for</span> <span class="o">+</span> <span class="n">slope_for</span> <span class="o">*</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Foreign cars&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">int_dom</span> <span class="o">+</span> <span class="n">slope_dom</span> <span class="o">*</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Domestic cars&#39;</span><span class="p">)</span>

<span class="c1"># Adding legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/435050ed689f2717b3c0224e92de1552a44f26385b4bd91773bc6eb23427e5ad.png" src="../_images/435050ed689f2717b3c0224e92de1552a44f26385b4bd91773bc6eb23427e5ad.png" />
</div>
</div>
<p>Vemos que estas líneas se ajustan mucho mejor a los datos, lo que coincide con el resultado de nuestras pruebas.</p>
<p>Hasta ahora sólo hemos visto la interacción entre una variable categórica (<code class="docutils literal notranslate"><span class="pre">doméstica</span></code>) y una variable numérica (<code class="docutils literal notranslate"><span class="pre">disp</span></code>). Aunque esto es fácil de visualizar, ya que permite diferentes pendientes para dos líneas, no es el único tipo de interacción que podemos utilizar en un modelo. También podemos considerar interacciones entre dos variables numéricas.</p>
<p>Consideremos el modelo</p>
<div class="math notranslate nohighlight">
\[
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,
\]</div>
<p>donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>,la eficiencia del combustible en millas por galón,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>, la cilindrada en pulgadas cúbicas,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> es <code class="docutils literal notranslate"><span class="pre">hp</span></code>, la potencia, en pies-libra por segundo.</p></li>
</ul>
<p>¿Cómo cambia <code class="docutils literal notranslate"><span class="pre">mpg</span></code> en función de <code class="docutils literal notranslate"><span class="pre">disp</span></code> en este modelo? Podemos reordenar algunos términos para ver cómo.</p>
<div class="math notranslate nohighlight">
\[
Y = \beta_0 + (\beta_1 + \beta_3 x_2) x_1 + \beta_2 x_2 + \epsilon
\]</div>
<p>Así, para un aumento de una unidad en <span class="math notranslate nohighlight">\(x_1\)</span> (<code class="docutils literal notranslate"><span class="pre">disp</span></code>), la media de <span class="math notranslate nohighlight">\(Y\)</span> (<code class="docutils literal notranslate"><span class="pre">mpg</span></code>) aumenta <span class="math notranslate nohighlight">\(\beta_1 + \beta_3 x_2\)</span>, ¡que es un valor diferente dependiendo del valor de <span class="math notranslate nohighlight">\(x_2\)</span> (<code class="docutils literal notranslate"><span class="pre">hp</span></code>)!</p>
<p>Como ahora trabajamos en tres dimensiones, este modelo no puede justificarse fácilmente mediante visualizaciones como el ejemplo anterior. En su lugar, tendremos que basarnos en una prueba.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># Fit the additive model</span>
<span class="n">mpg_disp_add_hp</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp + hp&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Fit the interaction model</span>
<span class="n">mpg_disp_int_hp</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp * hp&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Display the summary of the interaction model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mpg_disp_int_hp</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.755
Model:                            OLS   Adj. R-squared:                  0.753
Method:                 Least Squares   F-statistic:                     390.2
Date:                Tue, 19 Sep 2023   Prob (F-statistic):          1.73e-115
Time:                        21:35:42   Log-Likelihood:                -1062.4
No. Observations:                 383   AIC:                             2133.
Df Residuals:                     379   BIC:                             2148.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     52.4082      1.523     34.417      0.000      49.414      55.402
disp          -0.1002      0.007    -15.090      0.000      -0.113      -0.087
hp            -0.2198      0.020    -11.063      0.000      -0.259      -0.181
disp:hp        0.0006   5.16e-05     10.956      0.000       0.000       0.001
==============================================================================
Omnibus:                       53.388   Durbin-Watson:                   1.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.980
Skew:                           0.782   Prob(JB):                     7.17e-23
Kurtosis:                       4.986   Cond. No.                     2.49e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.49e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Usando <code class="docutils literal notranslate"><span class="pre">summary()</span></code> nos centramos en la fila para <code class="docutils literal notranslate"><span class="pre">disp:hp</span></code> que prueba,</p>
<div class="math notranslate nohighlight">
\[
H_0: \beta_3 = 0.
\]</div>
<p>De nuevo, vemos un valor p muy bajo, por lo que rechazamos el nulo (modelo aditivo) a favor del modelo de interacción. De nuevo, existe una prueba <span class="math notranslate nohighlight">\(F\)</span> equivalente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conduct an ANOVA comparison between the two models</span>
<span class="n">anova_results</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">mpg_disp_add_hp</span><span class="p">,</span> <span class="n">mpg_disp_int_hp</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">anova_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid          ssr  df_diff      ss_diff           F        Pr(&gt;F)
0     380.0  7576.553401      0.0          NaN         NaN           NaN
1     379.0  5754.231624      1.0  1822.321777  120.026443  1.887753e-24
</pre></div>
</div>
</div>
</div>
<p>Podemos examinar más detenidamente los coeficientes de nuestro modelo de interacción ajustado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the coefficients of the interaction model</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mpg_disp_int_hp</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    52.408200
disp         -0.100174
hp           -0.219820
disp:hp       0.000566
dtype: float64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_0 = 52.408\)</span> es la media estimada de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un coche con 0 <code class="docutils literal notranslate"><span class="pre">disp</span></code> y 0 <code class="docutils literal notranslate"><span class="pre">cv</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_1 = −0.100\)</span> es el cambio estimado en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de 1 <code class="docutils literal notranslate"><span class="pre">disp</span></code>, <strong>para un coche con 0 <code class="docutils literal notranslate"><span class="pre">hp</span></code></strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_2 = −0.219\)</span> es el cambio estimado en la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de 1 <code class="docutils literal notranslate"><span class="pre">hp</span></code>, <strong>para un coche con 0 <code class="docutils literal notranslate"><span class="pre">disp</span></code></strong>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\beta}_3 = 5.66\times 10^{-4}\)</span> es una estimación de la modificación del cambio en el promedio de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> por un aumento en <code class="docutils literal notranslate"><span class="pre">disp</span></code>, para un coche de un determinado <code class="docutils literal notranslate"><span class="pre">hp</span></code> (o viceversa).</p></li>
</ul>
<p>Este último coeficiente necesita más explicación. Recordemos la que hemos hecho antes</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + (\beta_1 + \beta_3 x_2) x_1 + \beta_2 x_2 + \epsilon.\]</div>
<p>Por lo tanto, nuestra estimación para <span class="math notranslate nohighlight">\(\beta_1 + \beta_3 x_2\)</span>, es
<span class="math notranslate nohighlight">\(\hat{\beta}_1 + \hat{\beta}_3 x_2\)</span>, que en este caso es</p>
<div class="math notranslate nohighlight">
\[-0.1001738 + 5.658269\times 10^{-4} x_2.\]</div>
<p>Esto significa que, para un aumento de un <code class="docutils literal notranslate"><span class="pre">disp</span></code> vemos un cambio estimado en el <code class="docutils literal notranslate"><span class="pre">mpg</span></code> medio de <span class="math notranslate nohighlight">\(-0.1001738 + 5.658269\times 10^{-4} x_2\)</span>. Por tanto, la relación entre <code class="docutils literal notranslate"><span class="pre">disp</span></code> y <code class="docutils literal notranslate"><span class="pre">mpg</span></code> depende de los <code class="docutils literal notranslate"><span class="pre">cv</span></code> del coche.</p>
<p>Así que para un coche con 50 <code class="docutils literal notranslate"><span class="pre">hp</span></code>, el cambio estimado en promedio <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de un <code class="docutils literal notranslate"><span class="pre">disp</span></code> es</p>
<div class="math notranslate nohighlight">
\[-0.1001738 + 5.658269\times 10^{-4} \cdot 50 = -0.0718824\]</div>
<p>Y para un coche con 350 <code class="docutils literal notranslate"><span class="pre">hp</span></code>, el cambio estimado en el promedio de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un aumento de un <code class="docutils literal notranslate"><span class="pre">disp</span></code> es de</p>
<div class="math notranslate nohighlight">
\[-0.1001738 + 5.658269\times 10^{-4} \cdot 350 = 0.0978657\]</div>
<p>¡Fíjate en que el signo ha cambiado!</p>
</section>
<section id="variables-categoricas">
<h1>Variables categóricas<a class="headerlink" href="#variables-categoricas" title="Permalink to this heading">#</a></h1>
<p>Hasta ahora  hemos limitado nuestro uso de variables categóricas a variables categóricas binarias. Específicamente, nos hemos limitado a variables ficticias que toman un valor de <code class="docutils literal notranslate"><span class="pre">0</span></code> o <code class="docutils literal notranslate"><span class="pre">1</span></code> y representan una variable categórica numéricamente.</p>
<p>Ahora hablaremos de las variables <strong>categóricas</strong>, con ellas, un usuario humano puede simplemente pensar en las categorías de una variable, y <code class="docutils literal notranslate"><span class="pre">Python</span></code> se encargará de las variables ficticias necesarias sin que el usuario tenga que hacer ninguna asignación 0/1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if column &#39;origin&#39; is of factor type</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
<p>Antes, cuando utilizábamos la variable  <code class="docutils literal notranslate"><span class="pre">domestic</span></code>, no era una variable factorial. Era simplemente una variable numérica que sólo tenía dos valores posibles, <code class="docutils literal notranslate"><span class="pre">1</span></code> para nacional y  <code class="docutils literal notranslate"><span class="pre">0</span></code> para extranjero. Vamos a crear una nueva variable “origen” que almacena la misma información, pero de una manera diferente.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modify the &#39;origin&#39; column based on the &#39;domestic&#39; column values</span>
<span class="n">autompg</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;origin&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;domestic&#39;</span>
<span class="n">autompg</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;domestic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;origin&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;foreign&#39;</span>

<span class="c1"># Display the head of the &#39;origin&#39; column</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8 cylinder 70 chevrolet chevelle malibu    domestic
8 cylinder 70 buick skylark 320            domestic
8 cylinder 70 plymouth satellite           domestic
8 cylinder 70 amc rebel sst                domestic
8 cylinder 70 ford torino                  domestic
Name: origin, dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert &#39;origin&#39; column to factor type</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ahora la variable <code class="docutils literal notranslate"><span class="pre">origin</span></code> almacena <code class="docutils literal notranslate"><span class="pre">&quot;domestic&quot;</span></code> para carros nacionales y <code class="docutils literal notranslate"><span class="pre">&quot;foreign&quot;</span></code> para los carros extranjeros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if column &#39;origin&#39; is of factor type</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Observe que python se ha encargado de crear las categorias correspondientes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the levels (unique values) of &#39;origin&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;domestic&#39;, &#39;foreign&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>Ahora, cuando comprobamos la estructura del conjunto de datos <code class="docutils literal notranslate"><span class="pre">autompg</span></code>, vemos que <code class="docutils literal notranslate"><span class="pre">origin</span></code> es una variable categórica.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the structure (info) of the DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 383 entries, 8 cylinder 70 chevrolet chevelle malibu to 4 cylinder 82 chevy s-10
Data columns (total 10 columns):
 #   Column    Non-Null Count  Dtype   
---  ------    --------------  -----   
 0   mpg       383 non-null    float64 
 1   cyl       383 non-null    category
 2   disp      383 non-null    float64 
 3   hp        383 non-null    float64 
 4   wt        383 non-null    float64 
 5   acc       383 non-null    float64 
 6   year      383 non-null    int64   
 7   origin    383 non-null    category
 8   domestic  383 non-null    int32   
 9   x3        383 non-null    float64 
dtypes: category(2), float64(6), int32(1), int64(1)
memory usage: 34.5+ KB
None
</pre></div>
</div>
</div>
</div>
<p>Las variables categóricas tienen <strong>niveles</strong> que son los posibles valores (categorías) que puede tomar la variable, en este caso extranjera o nacional.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the levels (unique values) of &#39;origin&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;origin&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;domestic&#39;, &#39;foreign&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>Recordemos que anteriormente hemos ajustado el modelo</p>
<div class="math notranslate nohighlight">
\[ Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon, \]</div>
<p>donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, la eficiencia del combustible en millas por galón,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>, la cilindrada en pulgadas cúbicas,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> es <code class="docutils literal notranslate"><span class="pre">domestic</span></code>,una variable ficticia en la que <code class="docutils literal notranslate"><span class="pre">1</span></code> indica un coche nacional.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the model with interaction between disp and domestic</span>
<span class="n">mod_dummy</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp * domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">mod_dummy</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept        46.054842
disp             -0.156924
domestic        -12.575471
disp:domestic     0.102518
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Así que aquí vemos que</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}_0 + \hat{\beta}_2 = 46.0548423 + -12.5754714 = 33.4793709\]</div>
<p>es la media estimada de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un coche <strong>doméstico</strong> con 0 <code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p>
<p>Ahora intentemos hacer lo mismo, pero utilizando nuestra nueva variable factorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the model with interaction between disp and origin</span>
<span class="n">mod_factor</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp * origin&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">mod_factor</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept                 33.479371
origin[T.foreign]         12.575471
disp                      -0.054405
disp:origin[T.foreign]    -0.102518
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Parece que no produce los mismos resultados. Enseguida nos damos cuenta de que el intercepto es diferente, al igual que el coeficiente que precede a <code class="docutils literal notranslate"><span class="pre">disp</span></code>. También observamos que los dos coeficientes restantes son de la misma magnitud que sus homólogos respectivos utilizando la variable nacional, pero con un signo diferente. ¿Por qué ocurre esto?</p>
<p>Resulta que al utilizar una variable factorial, <code class="docutils literal notranslate"><span class="pre">R</span></code> nos crea automáticamente una variable ficticia. Sin embargo, no es la variable ficticia que habíamos utilizado originalmente.</p>
<p><code class="docutils literal notranslate"><span class="pre">R</span></code> está ajustando el modelo</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon,\]</div>
<p>donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, la eficiencia del combustible en millas por galón,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>, el desplazamiento en pulgadas cúbicas,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> <strong>es una variable ficticia creada por <code class="docutils literal notranslate"><span class="pre">Python</span></code>.</strong> Utiliza <code class="docutils literal notranslate"><span class="pre">1</span></code> para representar un <strong>carro extranjero</strong>.</p></li>
</ul>
<p>Así que ahora,</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}_0 = 33.4793709\]</div>
<p>es la media estimada de “mpg” de un coche “nacional” con 0 “disp”, que es la misma que antes.</p>
<p>Cuando <code class="docutils literal notranslate"><span class="pre">Python</span></code> creó <span class="math notranslate nohighlight">\(x_2\)</span>, la variable ficticia, utilizó los carros nacionales como el nivel de <strong>referencia</strong>, que es el valor por defecto de la variable categórica. Así que cuando la variable ficticia es “0”, el modelo representa este nivel de referencia, que es nacional. (<code class="docutils literal notranslate"><span class="pre">Python</span></code> hace esta elección porque nacional va antes que extranjero alfabéticamente, ojo mirando las palabras en ingles claro está).</p>
<p>Así pues, los dos modelos tienen coeficientes estimados diferentes, pero debido a las distintas representaciones del modelo, en realidad son el mismo modelo.</p>
<section id="factores-con-mas-de-dos-niveles">
<h2>Factores con más de dos niveles<a class="headerlink" href="#factores-con-mas-de-dos-niveles" title="Permalink to this heading">#</a></h2>
<p>Consideremos ahora una variable factorial con más de dos niveles. En este conjunto de datos, <code class="docutils literal notranslate"><span class="pre">cyl</span></code> es un ejemplo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if column &#39;cyl&#39; is of factor type</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;category&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the levels (unique values) of &#39;cyl&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">categories</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64Index([4, 6, 8], dtype=&#39;int64&#39;)
</pre></div>
</div>
</div>
</div>
<p>Aquí la variable <code class="docutils literal notranslate"><span class="pre">cyl</span></code> tiene tres niveles posibles: <code class="docutils literal notranslate"><span class="pre">4</span></code>, <code class="docutils literal notranslate"><span class="pre">6</span></code> y <code class="docutils literal notranslate"><span class="pre">8</span></code>. Te preguntarás, ¿por qué no utilizar simplemente <code class="docutils literal notranslate"><span class="pre">cyl</span></code> como una variable numérica? Por supuesto que podría.</p>
<p>Sin embargo, eso forzaría a que la diferencia en mpg medio entre <code class="docutils literal notranslate"><span class="pre">4</span></code> y <code class="docutils literal notranslate"><span class="pre">6</span></code> cilindros fuera la misma que la diferencia en mpg medio entre <code class="docutils literal notranslate"><span class="pre">6</span></code> y <code class="docutils literal notranslate"><span class="pre">8</span></code> cilindros. Esto suele tener sentido para una variable continua, pero no para una variable discreta con tan pocos valores posibles. En el caso de esta variable, no existe un motor de 7 cilindros ni un motor de 6,23 cilindros en vehículos personales. Por estas razones, consideraremos simplemente que <code class="docutils literal notranslate"><span class="pre">cyl</span></code> es categórica. Se trata de una decisión que normalmente habrá que tomar con variables ordinales. A menudo, con un gran número de categorías, la decisión de tratarlas como variables numéricas es apropiada porque, de lo contrario, se necesitaría un gran número de variables ficticias para representar estas variables.</p>
<p>Definamos tres variables ficticias relacionadas con la variable factorial <code class="docutils literal notranslate"><span class="pre">cyl</span></code>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
v_1 =
  \begin{cases}
   1 &amp; \text{4 cylinder} \\
   0       &amp; \text{not 4 cylinder}
  \end{cases}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
v_2 =
  \begin{cases}
   1 &amp; \text{6 cylinder} \\
   0       &amp; \text{not 6 cylinder}
  \end{cases}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
v_3 =
  \begin{cases}
   1 &amp; \text{8 cylinder} \\
   0       &amp; \text{not 8 cylinder}
  \end{cases}
\end{split}\]</div>
<p>Ahora, vamos a ajustar un modelo aditivo en <code class="docutils literal notranslate"><span class="pre">Python</span></code>, utilizando <code class="docutils literal notranslate"><span class="pre">mpg</span></code> como respuesta, y <code class="docutils literal notranslate"><span class="pre">disp</span></code> y <code class="docutils literal notranslate"><span class="pre">cyl</span></code> como predictores. Esto debería ser un modelo que utiliza “tres líneas de regresión” para modelar <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, uno para cada uno de los posibles niveles de <code class="docutils literal notranslate"><span class="pre">cyl</span></code>. Todos ellos tendrán la misma pendiente (ya que es un modelo aditivo), pero cada uno tendrá su propio intercepto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the additive model with disp and cyl</span>
<span class="n">mpg_disp_add_cyl</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;mpg ~ disp + C(cyl)&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.690
Model:                            OLS   Adj. R-squared:                  0.687
Method:                 Least Squares   F-statistic:                     280.8
Date:                Tue, 19 Sep 2023   Prob (F-statistic):           6.24e-96
Time:                        21:35:42   Log-Likelihood:                -1107.9
No. Observations:                 383   AIC:                             2224.
Df Residuals:                     379   BIC:                             2240.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept      34.9993      0.822     42.561      0.000      33.382      36.616
C(cyl)[T.6]    -3.6332      0.950     -3.823      0.000      -5.502      -1.764
C(cyl)[T.8]    -2.0360      1.722     -1.182      0.238      -5.423       1.351
disp           -0.0522      0.007     -7.505      0.000      -0.066      -0.039
==============================================================================
Omnibus:                       55.103   Durbin-Watson:                   0.955
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.808
Skew:                           0.810   Prob(JB):                     2.87e-23
Kurtosis:                       4.970   Cond. No.                     2.00e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large,  2e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>La pregunta es, ¿cuál es el modelo que <code class="docutils literal notranslate"><span class="pre">Python</span></code> ha ajustado aquí? Ha elegido utilizar el modelo</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon,\]</div>
<p>donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, la eficiencia del combustible en millas por galón,</p></li>
<li><p><span class="math notranslate nohighlight">\(x\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>, el desplazamiento en pulgadas cúbicas,</p></li>
<li><p><span class="math notranslate nohighlight">\(v_2\)</span> y <span class="math notranslate nohighlight">\(v_3\)</span> son las variables ficticias definidas anteriormente.</p></li>
</ul>
<p>¿Por qué <code class="docutils literal notranslate"><span class="pre">R</span></code> no utiliza <span class="math notranslate nohighlight">\(v_1\)</span>? Básicamente porque no es necesario. Para crear tres líneas, sólo necesita dos variables ficticias, ya que está utilizando un nivel de referencia, que en este caso es un coche de 4 cilindros. Los tres “submodelos” son entonces:</p>
<ul class="simple">
<li><p>4 Cilindro: <span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x + \epsilon\)</span></p></li>
<li><p>6 Cilindro: <span class="math notranslate nohighlight">\(Y = (\beta_0 + \beta_2) + \beta_1 x + \epsilon\)</span></p></li>
<li><p>8 Cilindro: <span class="math notranslate nohighlight">\(Y = (\beta_0 + \beta_3) + \beta_1 x + \epsilon\)</span></p></li>
</ul>
<p>Obsérvese que todos tienen la misma pendiente. Sin embargo, utilizando las dos variables ficticias obtenemos los tres interceptos.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> es el promedio de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> para un coche de 4 cilindros con 0 <code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0 + \beta_2\)</span> es la media de “mpg” de un coche de 6 cilindros con 0
disp`.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0 + \beta_3\)</span> es la media de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> de un coche de 8 cilindros con 0
<code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p></li>
</ul>
<p>Como el nivel de referencia es el de 4 cilindros, <span class="math notranslate nohighlight">\(\beta_0\)</span> es específico de 4 cilindros, pero <span class="math notranslate nohighlight">\(\beta_2\)</span> y <span class="math notranslate nohighlight">\(\beta_3\)</span> se utilizan para representar cantidades relativas a 4 cilindros.</p>
<p>Como hemos hecho antes, podemos extraer estos interceptos y pendientes para las tres rectas, y trazarlos en consecuencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>  <span class="c1"># use smf instead of sm for formula API</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Ensure the &#39;cyl&#39; column is a categorical column</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>

<span class="c1"># Create a linear model object</span>
<span class="n">mpg_disp_add_cyl</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;mpg ~ disp + C(cyl)&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Get the intercept and slope coefficients for each cylinder type</span>
<span class="n">int_4cyl</span> <span class="o">=</span> <span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span>
<span class="n">slope_4cyl</span> <span class="o">=</span> <span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;disp&#39;</span><span class="p">]</span>

<span class="c1"># 6 and 8 cylinders&#39; intercepts will be the sum of the main intercept and their respective coefficients</span>
<span class="n">int_6cyl</span> <span class="o">=</span> <span class="n">int_4cyl</span> <span class="o">+</span> <span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;C(cyl)[T.6]&#39;</span><span class="p">]</span>
<span class="n">int_8cyl</span> <span class="o">=</span> <span class="n">int_4cyl</span> <span class="o">+</span> <span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;C(cyl)[T.8]&#39;</span><span class="p">]</span>

<span class="c1"># Slopes for 6 and 8 cylinders remain the same as 4 cylinder&#39;s slope</span>
<span class="n">slope_6cyl</span> <span class="o">=</span> <span class="n">slope_4cyl</span>
<span class="n">slope_8cyl</span> <span class="o">=</span> <span class="n">slope_4cyl</span>

<span class="c1"># Create a plot of mpg vs. disp, colored by cylinder type</span>
<span class="n">plot_colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Darkorange&quot;</span><span class="p">,</span> <span class="s2">&quot;Darkgrey&quot;</span><span class="p">,</span> <span class="s2">&quot;Dodgerblue&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="c1"># Scatter plots for each cylinder type</span>
<span class="k">for</span> <span class="n">cyl</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">plot_colors</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cyl</span><span class="p">][</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> 
                <span class="n">autompg</span><span class="p">[</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cyl</span><span class="p">][</span><span class="s2">&quot;mpg&quot;</span><span class="p">],</span> 
                <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cyl</span><span class="si">}</span><span class="s2"> Cylinder&quot;</span><span class="p">)</span>

<span class="c1"># Add a regression line for each cylinder type</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">int_4cyl</span> <span class="o">+</span> <span class="n">slope_4cyl</span> <span class="o">*</span> <span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plot_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">int_6cyl</span> <span class="o">+</span> <span class="n">slope_6cyl</span> <span class="o">*</span> <span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plot_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">int_8cyl</span> <span class="o">+</span> <span class="n">slope_8cyl</span> <span class="o">*</span> <span class="n">autompg</span><span class="p">[</span><span class="s2">&quot;disp&quot;</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plot_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Add a legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Set the plot title and labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MPG vs. Displacement by Cylinder Type&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Displacement (cu. in.)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MPG&quot;</span><span class="p">)</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f2eb30e40c652434d7d35adefd571f78ddfa9e7063793e879a5ded6aa1f77cb0.png" src="../_images/f2eb30e40c652434d7d35adefd571f78ddfa9e7063793e879a5ded6aa1f77cb0.png" />
</div>
</div>
<p>En este gráfico, tenemos</p>
<ul class="simple">
<li><p>4 Cilindro: puntos naranjas, línea naranja continua.</p></li>
<li><p>6 Cilindro: puntos grises, línea  gris continua.</p></li>
<li><p>8 cilindros: puntos azules, línea azul continua.</p></li>
</ul>
<p>El extraño resultado aquí es que estamos estimando que los carros de 8 cilindros tienen mejor eficiencia de combustible que los de 6 cilindros en <strong>cualquier</strong> cilindrada. La línea azul  está siempre por encima de la línea gris discontinua. No parece correcto. Quizás para motores de gran cilindrada podría ser cierto, pero parece erróneo para cilindradas medias y bajas.</p>
<p>Para intentar arreglar esto, intentaremos usar un modelo de interacción, es decir, en lugar de simplemente tres interceptos y una pendiente, permitiremos tres pendientes. Una vez más, dejaremos que <code class="docutils literal notranslate"><span class="pre">Python</span></code> haga su trabajo, y luego averiguaremos qué modelo ha aplicado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>

<span class="c1"># Fit the model with an interaction term</span>
<span class="n">mpg_disp_int_cyl</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp * cyl&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mpg_disp_int_cyl</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.722
Model:                            OLS   Adj. R-squared:                  0.718
Method:                 Least Squares   F-statistic:                     195.4
Date:                Tue, 19 Sep 2023   Prob (F-statistic):          2.66e-102
Time:                        21:35:42   Log-Likelihood:                -1087.2
No. Observations:                 383   AIC:                             2186.
Df Residuals:                     377   BIC:                             2210.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept        43.5905      1.556     28.015      0.000      40.531      46.650
cyl[T.6]        -13.2003      3.499     -3.773      0.000     -20.080      -6.321
cyl[T.8]        -20.8571      3.444     -6.057      0.000     -27.628     -14.086
disp             -0.1307      0.014     -9.362      0.000      -0.158      -0.103
disp:cyl[T.6]     0.0830      0.020      4.168      0.000       0.044       0.122
disp:cyl[T.8]     0.1082      0.017      6.550      0.000       0.076       0.141
==============================================================================
Omnibus:                       53.697   Durbin-Watson:                   0.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.712
Skew:                           0.789   Prob(JB):                     8.20e-23
Kurtosis:                       4.970   Cond. No.                     5.07e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 5.07e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Python ha vuelto a elegir los carros de 4 cilindros como nivel de referencia, pero esto también afecta a los términos de interacción. <code class="docutils literal notranslate"><span class="pre">python</span></code> ha ajustado el modelo.</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \gamma_2 x v_2 + \gamma_3 x v_3 + \epsilon\]</div>
<p>Estamos utilizando <span class="math notranslate nohighlight">\(\gamma\)</span> como un parámetro <span class="math notranslate nohighlight">\(\beta\)</span> para simplificar, de modo que, por ejemplo <span class="math notranslate nohighlight">\(\beta_2\)</span> y <span class="math notranslate nohighlight">\(\gamma_2\)</span> son ambos asociados con <span class="math notranslate nohighlight">\(v_2\)</span>.</p>
<p>Ahora, los tres “submodelos” son:</p>
<ul class="simple">
<li><p>4 Cilindro: <span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x + \epsilon\)</span>.</p></li>
<li><p>6 Cilindro::
<span class="math notranslate nohighlight">\(Y = (\beta_0 + \beta_2) + (\beta_1 + \gamma_2) x + \epsilon\)</span>.</p></li>
<li><p>8 Cilindro:
<span class="math notranslate nohighlight">\(Y = (\beta_0 + \beta_3) + (\beta_1 + \gamma_3) x + \epsilon\)</span>.</p></li>
</ul>
<p>Interpretando algunos parámetros y coeficientes entonces:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\((\beta_0 + \beta_2)\)</span> es el promedio de <code class="docutils literal notranslate"><span class="pre">mpg</span></code> de un coche de 6 cilindros con
0 <code class="docutils literal notranslate"><span class="pre">disp</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\((\hat{\beta}_1 + \hat{\gamma}_3) = -0.1306935 + 0.1081714 = -0.0225221\)</span>
es el cambio estimado en el promedio de “mpg” para un aumento de un  <code class="docutils literal notranslate"><span class="pre">disp</span></code> , para un coche de 8 cilindros.</p></li>
</ul>
<p>Así que, como hemos visto antes, <span class="math notranslate nohighlight">\(\beta_2\)</span> y <span class="math notranslate nohighlight">\(\beta_3\)</span> cambian los interceptos para carros de 6 y 8 cilindros en relación con el nivel de referencia de <span class="math notranslate nohighlight">\(\beta_0\)</span> para carros de 4 cilindros.</p>
<p>Ahora, de forma similar, <span class="math notranslate nohighlight">\(\gamma_2\)</span> y <span class="math notranslate nohighlight">\(\gamma_3\)</span> cambian las pendientes de los carros de 6 y 8 cilindros en relación con el nivel de referencia de <span class="math notranslate nohighlight">\(\beta_1\)</span> para los carros de 4 cilindros.</p>
<p>Una vez más, extraemos los coeficientes y trazamos los resultados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Interaction plot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;disp&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;mpg&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;cyl&#39;</span><span class="p">,</span> <span class="n">ci</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Interaction between disp and cylinder type on mpg&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05095ee347cff69868c7e788a86d42fd06508b805db1c9a3b121ae2585d71eda.png" src="../_images/05095ee347cff69868c7e788a86d42fd06508b805db1c9a3b121ae2585d71eda.png" />
</div>
</div>
<p>Esto tiene mucho mejor aspecto. Podemos ver que, en el caso de los carros de cilindrada media, los carros de 6 cilindros obtienen ahora mejores resultados que los de 8 cilindros, lo que parece mucho más razonable que antes.</p>
<p>Para justificar completamente el modelo de interacción (es decir, una pendiente única para cada nivel de <code class="docutils literal notranslate"><span class="pre">cyl</span></code>) en comparación con el modelo aditivo (pendiente única), podemos realizar una prueba <span class="math notranslate nohighlight">\(F\)</span>. Observe primero que no hay ninguna prueba <span class="math notranslate nohighlight">\(t\)</span> que pueda hacer esto, ya que la diferencia entre los dos modelos no es un único parámetro.</p>
<p>Haremos la prueba,</p>
<p><span class="math notranslate nohighlight">\(H_0: \gamma_2 = \gamma_3 = 0\)</span></p>
<p>que representa las líneas de regresión paralelas que vimos antes,</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon.\]</div>
<p>De nuevo, se trata de una diferencia de dos parámetros, por lo que no será útil ninguna prueba <span class="math notranslate nohighlight">\(t\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now, use anova_lm to compare</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">mpg_disp_add_cyl</span><span class="p">,</span> <span class="n">mpg_disp_int_cyl</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid          ssr  df_diff     ss_diff          F        Pr(&gt;F)
0     379.0  7299.524999      0.0         NaN        NaN           NaN
1     377.0  6551.731850      2.0  747.793149  21.514771  1.419369e-09
</pre></div>
</div>
</div>
</div>
<p>Como era de esperar, vemos un valor p muy bajo y, por tanto, rechazamos la nulidad. Preferimos el modelo de interacción al modelo aditivo.</p>
<p>Recapitulando un poco:</p>
<ul class="simple">
<li><p>Modelo Nulo
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \epsilon\)</span></p>
<ul>
<li><p>Número de parámetros: <span class="math notranslate nohighlight">\(q = 4\)</span></p></li>
</ul>
</li>
<li><p>Modelo completo:
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x + \beta_2 v_2 + \beta_3 v_3 + \gamma_2 x v_2 + \gamma_3 x v_3 + \epsilon\)</span></p>
<ul>
<li><p>Número de parámetros: <span class="math notranslate nohighlight">\(p = 6\)</span></p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">difference</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mpg_disp_int_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">mpg_disp_add_cyl</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">difference</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
</pre></div>
</div>
</div>
</div>
<p>Vemos que hay una diferencia de dos parámetros, que también aparece en la tabla ANOVA resultante de <code class="docutils literal notranslate"><span class="pre">R</span></code>. Observe que los dos valores siguientes también aparecen en la tabla ANOVA.</p>
</section>
</section>
<section id="parametrizacion">
<h1>Parametrización<a class="headerlink" href="#parametrizacion" title="Permalink to this heading">#</a></h1>
<p>Hasta ahora hemos dejado que <code class="docutils literal notranslate"><span class="pre">Python</span></code> decida cómo crear las variables ficticias y, por lo tanto, <code class="docutils literal notranslate"><span class="pre">Python</span></code> ha decidido la parametrización de los modelos. Para ilustrar la capacidad de utilizar parametrizaciones alternativas, vamos a recrear los datos, pero creando directamente las variables ficticias nosotros mismos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating new dataframe</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;v1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;v2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;v3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">autompg</span><span class="p">[</span><span class="s1">&#39;cyl&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">new_param_data</span> <span class="o">=</span> <span class="n">autompg</span><span class="p">[[</span><span class="s1">&#39;mpg&#39;</span><span class="p">,</span> <span class="s1">&#39;disp&#39;</span><span class="p">,</span> <span class="s1">&#39;v1&#39;</span><span class="p">,</span> <span class="s1">&#39;v2&#39;</span><span class="p">,</span> <span class="s1">&#39;v3&#39;</span><span class="p">]]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">new_param_data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                             mpg   disp  v1  v2  v3
8 cylinder 70 chevrolet chevelle malibu     18.0  307.0   0   0   1
8 cylinder 70 buick skylark 320             15.0  350.0   0   0   1
8 cylinder 70 plymouth satellite            18.0  318.0   0   0   1
8 cylinder 70 amc rebel sst                 16.0  304.0   0   0   1
8 cylinder 70 ford torino                   17.0  302.0   0   0   1
8 cylinder 70 ford galaxie 500              15.0  429.0   0   0   1
8 cylinder 70 chevrolet impala              14.0  454.0   0   0   1
8 cylinder 70 plymouth fury iii             14.0  440.0   0   0   1
8 cylinder 70 pontiac catalina              14.0  455.0   0   0   1
8 cylinder 70 amc ambassador dpl            15.0  390.0   0   0   1
8 cylinder 70 dodge challenger se           15.0  383.0   0   0   1
8 cylinder 70 plymouth &#39;cuda 340            14.0  340.0   0   0   1
8 cylinder 70 chevrolet monte carlo         15.0  400.0   0   0   1
8 cylinder 70 buick estate wagon (sw)       14.0  455.0   0   0   1
4 cylinder 70 toyota corona mark ii         24.0  113.0   1   0   0
6 cylinder 70 plymouth duster               22.0  198.0   0   1   0
6 cylinder 70 amc hornet                    18.0  199.0   0   1   0
6 cylinder 70 ford maverick                 21.0  200.0   0   1   0
4 cylinder 70 datsun pl510                  27.0   97.0   1   0   0
4 cylinder 70 volkswagen 1131 deluxe sedan  26.0   97.0   1   0   0
</pre></div>
</div>
</div>
</div>
<p>Ahora,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code>es <code class="docutils literal notranslate"><span class="pre">mpg</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>, el desplazamiento en pulgadas cúbicas,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1</span></code>, <code class="docutils literal notranslate"><span class="pre">v2</span></code>, y <code class="docutils literal notranslate"><span class="pre">v3</span></code> son variables ficticias como se definieron anteriormente.</p></li>
</ul>
<p>En primer lugar vamos a tratar de ajustar un modelo aditivo utilizando <code class="docutils literal notranslate"><span class="pre">x</span></code>, en este caso somos nosotros quienes definimos cual es la variable de referencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linear models</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp + v1 + v2 &#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_param_data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.690
Model:                            OLS   Adj. R-squared:                  0.687
Method:                 Least Squares   F-statistic:                     280.8
Date:                Tue, 19 Sep 2023   Prob (F-statistic):           6.24e-96
Time:                        21:35:46   Log-Likelihood:                -1107.9
No. Observations:                 383   AIC:                             2224.
Df Residuals:                     379   BIC:                             2240.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     32.9633      2.437     13.527      0.000      28.172      37.755
disp          -0.0522      0.007     -7.505      0.000      -0.066      -0.039
v1             2.0360      1.722      1.182      0.238      -1.351       5.423
v2            -1.5972      1.093     -1.462      0.145      -3.746       0.551
==============================================================================
Omnibus:                       55.103   Durbin-Watson:                   0.955
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.808
Skew:                           0.810   Prob(JB):                     2.87e-23
Kurtosis:                       4.970   Cond. No.                     3.10e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.1e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Esto se debe a que</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{1} = v_1 + v_2 + v_3\]</div>
<p>lo que significa que <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span>, <span class="math notranslate nohighlight">\(v_1\)</span>, <span class="math notranslate nohighlight">\(v_2\)</span>, y <span class="math notranslate nohighlight">\(v_3\)</span> son linealmente dependientes. Esto haría que la matriz <span class="math notranslate nohighlight">\(X^\top X\)</span> fuera singular, pero tenemos que ser capaces de invertirlo para resolver las ecuaciones normales y obtener <span class="math notranslate nohighlight">\(\hat{\beta}.\)</span> Con el intercepto, <code class="docutils literal notranslate"><span class="pre">v1</span></code>, y <code class="docutils literal notranslate"><span class="pre">v2</span></code>, <code class="docutils literal notranslate"><span class="pre">Python</span></code> puede hacer los necesarios “tres interceptos”. Por lo tanto, en este caso <code class="docutils literal notranslate"><span class="pre">v3</span></code> es el nivel de referencia.</p>
<p>Si eliminamos el intercepto, entonces podemos obtener directamente los “tres interceptos” sin un nivel de referencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model2</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ 0 + disp + v1 + v2 + v3&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_param_data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.690
Model:                            OLS   Adj. R-squared:                  0.687
Method:                 Least Squares   F-statistic:                     280.8
Date:                Mon, 18 Sep 2023   Prob (F-statistic):           6.28e-96
Time:                        12:43:17   Log-Likelihood:                -1107.9
No. Observations:                 383   AIC:                             2224.
Df Residuals:                     379   BIC:                             2240.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
disp          -0.0522      0.007     -7.504      0.000      -0.066      -0.038
v1            34.9984      0.822     42.561      0.000      33.382      36.615
v2            31.3645      1.593     19.695      0.000      28.233      34.496
v3            32.9609      2.437     13.525      0.000      28.169      37.752
==============================================================================
Omnibus:                       55.099   Durbin-Watson:                   0.955
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              103.795
Skew:                           0.810   Prob(JB):                     2.89e-23
Kurtosis:                       4.970   Cond. No.                     2.95e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.95e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Aquí, estamos ajustando el modelo</p>
<div class="math notranslate nohighlight">
\[
Y = \mu_1 v_1 + \mu_2 v_2 + \mu_3 v_3 + \beta x +\epsilon.
\]</div>
<p>Así tenemos:</p>
<ul class="simple">
<li><p>4 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_1 + \beta x + \epsilon\)</span></p></li>
<li><p>6 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_2 + \beta x + \epsilon\)</span></p></li>
<li><p>8 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_3 + \beta x + \epsilon\)</span></p></li>
</ul>
<p>También podríamos hacer algo parecido con el modelo de interacción, y dar a cada línea una intercepción y una pendiente, sin necesidad de un nivel de referencia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model3</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ 0 + v1 + v2 + v3 + disp:v1 + disp:v2 + disp:v3&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">new_param_data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model3</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.721
Model:                            OLS   Adj. R-squared:                  0.718
Method:                 Least Squares   F-statistic:                     195.3
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          2.72e-102
Time:                        12:44:24   Log-Likelihood:                -1087.2
No. Observations:                 383   AIC:                             2186.
Df Residuals:                     377   BIC:                             2210.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
v1            43.5856      1.556     28.013      0.000      40.526      46.645
v2            30.3903      3.134      9.698      0.000      24.228      36.552
v3            22.7335      3.072      7.400      0.000      16.693      28.774
disp:v1       -0.1307      0.014     -9.360      0.000      -0.158      -0.103
disp:v2       -0.0477      0.014     -3.360      0.001      -0.076      -0.020
disp:v3       -0.0225      0.009     -2.552      0.011      -0.040      -0.005
==============================================================================
Omnibus:                       53.684   Durbin-Watson:                   0.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.680
Skew:                           0.789   Prob(JB):                     8.33e-23
Kurtosis:                       4.970   Cond. No.                     2.66e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.66e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[ Y = \mu_1 v_1 + \mu_2 v_2 + \mu_3 v_3 + \beta x +\epsilon.\]</div>
<ul class="simple">
<li><p>4 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_1 + \beta_1 x + \epsilon\)</span></p></li>
<li><p>6 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_2 + \beta_2 x + \epsilon\)</span></p></li>
<li><p>8 Cilindro: <span class="math notranslate nohighlight">\(Y = \mu_3 + \beta_3 x + \epsilon\)</span></p></li>
</ul>
<p>Utilizando los datos originales, tenemos (al menos) tres formas equivalentes de especificar el modelo de interacción con <code class="docutils literal notranslate"><span class="pre">Python</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model4</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp * cyl&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model4</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.721
Model:                            OLS   Adj. R-squared:                  0.718
Method:                 Least Squares   F-statistic:                     195.3
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          2.72e-102
Time:                        12:45:15   Log-Likelihood:                -1087.2
No. Observations:                 383   AIC:                             2186.
Df Residuals:                     377   BIC:                             2210.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept        43.5856      1.556     28.013      0.000      40.526      46.645
cyl[T.6]        -13.1953      3.499     -3.771      0.000     -20.075      -6.316
cyl[T.8]        -20.8522      3.444     -6.055      0.000     -27.624     -14.081
disp             -0.1307      0.014     -9.360      0.000      -0.158      -0.103
disp:cyl[T.6]     0.0829      0.020      4.166      0.000       0.044       0.122
disp:cyl[T.8]     0.1081      0.017      6.547      0.000       0.076       0.141
==============================================================================
Omnibus:                       53.684   Durbin-Watson:                   0.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.680
Skew:                           0.789   Prob(JB):                     8.33e-23
Kurtosis:                       4.970   Cond. No.                     5.07e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 5.07e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model5</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ 0 + cyl + disp:cyl&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model5</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.721
Model:                            OLS   Adj. R-squared:                  0.718
Method:                 Least Squares   F-statistic:                     195.3
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          2.72e-102
Time:                        12:46:03   Log-Likelihood:                -1087.2
No. Observations:                 383   AIC:                             2186.
Df Residuals:                     377   BIC:                             2210.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
cyl[4]         43.5856      1.556     28.013      0.000      40.526      46.645
cyl[6]         30.3903      3.134      9.698      0.000      24.228      36.552
cyl[8]         22.7335      3.072      7.400      0.000      16.693      28.774
disp:cyl[4]    -0.1307      0.014     -9.360      0.000      -0.158      -0.103
disp:cyl[6]    -0.0477      0.014     -3.360      0.001      -0.076      -0.020
disp:cyl[8]    -0.0225      0.009     -2.552      0.011      -0.040      -0.005
==============================================================================
Omnibus:                       53.684   Durbin-Watson:                   0.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.680
Skew:                           0.789   Prob(JB):                     8.33e-23
Kurtosis:                       4.970   Cond. No.                     2.66e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.66e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model6</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ 0 + disp + cyl + disp:cyl&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model6</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.721
Model:                            OLS   Adj. R-squared:                  0.718
Method:                 Least Squares   F-statistic:                     195.3
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          2.72e-102
Time:                        12:46:15   Log-Likelihood:                -1087.2
No. Observations:                 383   AIC:                             2186.
Df Residuals:                     377   BIC:                             2210.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
cyl[4]           43.5856      1.556     28.013      0.000      40.526      46.645
cyl[6]           30.3903      3.134      9.698      0.000      24.228      36.552
cyl[8]           22.7335      3.072      7.400      0.000      16.693      28.774
disp             -0.1307      0.014     -9.360      0.000      -0.158      -0.103
disp:cyl[T.6]     0.0829      0.020      4.166      0.000       0.044       0.122
disp:cyl[T.8]     0.1081      0.017      6.547      0.000       0.076       0.141
==============================================================================
Omnibus:                       53.684   Durbin-Watson:                   0.839
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.680
Skew:                           0.789   Prob(JB):                     8.33e-23
Kurtosis:                       4.970   Cond. No.                     4.05e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>Todos se ajustan al mismo modelo, cada uno con seis parámetros, pero los coeficientes significan cosas ligeramente diferentes en cada uno. Sin embargo, una vez interpretados como pendientes e interceptos para las “tres líneas”, tendrán el mismo resultado.</p>
</section>
<section id="creacion-de-modelos-mas-amplios">
<h1>Creación de modelos más amplios<a class="headerlink" href="#creacion-de-modelos-mas-amplios" title="Permalink to this heading">#</a></h1>
<p>Ahora que hemos visto cómo incorporar predictores categóricos así como términos de interacción, podemos empezar a construir modelos mucho más grandes y flexibles que potencialmente pueden ajustarse mejor a los datos.</p>
<p>Definamos un modelo “grande”,</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + \epsilon.\]</div>
<p>Aquí,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es <code class="docutils literal notranslate"><span class="pre">mpg</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> es <code class="docutils literal notranslate"><span class="pre">disp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> es <code class="docutils literal notranslate"><span class="pre">hp</span></code>.</p></li>
<li><p><span class="math notranslate nohighlight">\(x_3\)</span> es <code class="docutils literal notranslate"><span class="pre">domestic</span></code>, que es una variable ficticia que definimos, donde <code class="docutils literal notranslate"><span class="pre">1</span></code> es un vehículo nacional.</p></li>
</ul>
<p>En primer lugar, hemos incluido un nuevo término <span class="math notranslate nohighlight">\(x_1 x_2 x_3\)</span> que es una interacción de tres vías. Los términos de interacción pueden ser cada vez mayores, hasta el número de predictores del modelo.</p>
<p>Dado que estamos utilizando el término de interacción de tres vías, también utilizamos todas las posibles interacciones de dos vías, así como cada uno de los términos de primer orden (<strong>efecto principal</strong>). Este es el concepto de <strong>jerarquía</strong>. Cada vez que un término de “orden superior” está en un modelo, los términos de “orden inferior” relacionados también deben incluirse. Matemáticamente, su inclusión o exclusión es a veces irrelevante, pero desde el punto de vista de la interpretación, es mejor seguir las reglas de la jerarquía.</p>
<p>Hagamos algunos reordenamientos para obtener un “coeficiente” delante de <span class="math notranslate nohighlight">\(x_1\)</span>.</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_2 x_2 + \beta_3 x_3 + \beta_6 x_2 x_3 + (\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3)x_1 + \epsilon.\]</div>
<p>En concreto, el “coeficiente” delante de <span class="math notranslate nohighlight">\(x_1\)</span> es</p>
<div class="math notranslate nohighlight">
\[(\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3).\]</div>
<p>Hablemos de este “coeficiente” para ayudarnos a comprender la idea de la <em>flexibilidad</em> de un modelo. Recordemos que</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_1\)</span> es el coeficiente de un término de primer orden,</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_4\)</span> y <span class="math notranslate nohighlight">\(\beta_5\)</span> son coeficientes para interacciones bidireccionales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_7\)</span> es el coeficiente para la interacción de tres vías.</p></li>
</ul>
<p>Si las interacciones de dos y tres vías no estuvieran en el modelo, el “coeficiente” completo sería simplemente</p>
<div class="math notranslate nohighlight">
\[\beta_1.\]</div>
<p>Así, independientemente de los valores de <span class="math notranslate nohighlight">\(x_2\)</span> y <span class="math notranslate nohighlight">\(x_3\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span> determinaría la relación entre <span class="math notranslate nohighlight">\(x_1\)</span> (<code class="docutils literal notranslate"><span class="pre">disp</span></code>) y <span class="math notranslate nohighlight">\(Y\)</span> (<code class="docutils literal notranslate"><span class="pre">mpg</span></code>).</p>
<p>Con la adición de las interacciones bidireccionales, ahora el “coeficiente” sería</p>
<div class="math notranslate nohighlight">
\[(\beta_1 + \beta_4 x_2 + \beta_5 x_3).\]</div>
<p>Ahora, cambiar <span class="math notranslate nohighlight">\(x_1\)</span> (<code class="docutils literal notranslate"><span class="pre">disp</span></code>) tiene un efecto diferente en <span class="math notranslate nohighlight">\(Y\)</span> (<code class="docutils literal notranslate"><span class="pre">mpg</span></code>), dependiendo de los valores de <span class="math notranslate nohighlight">\(x_2\)</span> y <span class="math notranslate nohighlight">\(x_3\)</span>.</p>
<p>Por último, añadiendo la interacción de tres vías se obtiene el “coeficiente” completo</p>
<div class="math notranslate nohighlight">
\[(\beta_1 + \beta_4 x_2 + \beta_5 x_3 + \beta_7 x_2 x_3)\]</div>
<p>que es aún más flexible. Ahora cambiar <span class="math notranslate nohighlight">\(x_1\)</span> (<code class="docutils literal notranslate"><span class="pre">disp</span></code>) tiene un efecto diferente en <span class="math notranslate nohighlight">\(Y\)</span> (<code class="docutils literal notranslate"><span class="pre">mpg</span></code>), dependiendo de los valores de <span class="math notranslate nohighlight">\(x_2\)</span> y <span class="math notranslate nohighlight">\(x_3\)</span>, pero de una manera más flexible que podemos ver con un poco más de reordenación. Ahora el “coeficiente” delante de <span class="math notranslate nohighlight">\(x_3\)</span> en este “coeficiente” es depende de <span class="math notranslate nohighlight">\(x_2\)</span>.</p>
<div class="math notranslate nohighlight">
\[(\beta_1 + \beta_4 x_2 + (\beta_5 + \beta_7 x_2) x_3)\]</div>
<p>Es tan flexible que resulta difícil de interpretar.</p>
<p>Vamos a ajustar este modelo de interacción de tres vías en <code class="docutils literal notranslate"><span class="pre">Python</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">big_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp * hp * domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">big_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.760
Model:                            OLS   Adj. R-squared:                  0.756
Method:                 Least Squares   F-statistic:                     169.7
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          4.53e-112
Time:                        12:47:33   Log-Likelihood:                -1058.7
No. Observations:                 383   AIC:                             2133.
Df Residuals:                     375   BIC:                             2165.
Df Model:                           7                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           60.6458      6.600      9.188      0.000      47.668      73.624
disp                -0.1416      0.063     -2.232      0.026      -0.266      -0.017
hp                  -0.3545      0.081     -4.364      0.000      -0.514      -0.195
disp:hp              0.0014      0.001      2.035      0.043    4.62e-05       0.003
domestic           -12.5729      7.064     -1.780      0.076     -26.464       1.318
disp:domestic        0.0493      0.064      0.771      0.441      -0.077       0.175
hp:domestic          0.1851      0.087      2.126      0.034       0.014       0.356
disp:hp:domestic    -0.0009      0.001     -1.354      0.177      -0.002       0.000
==============================================================================
Omnibus:                       51.189   Durbin-Watson:                   1.080
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              111.254
Skew:                           0.707   Prob(JB):                     6.94e-25
Kurtosis:                       5.230   Cond. No.                     2.19e+06
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.19e+06. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<p>¿Necesitamos un modelo tan grande? Probemos primero la necesidad del término de interacción de tres vías. Es decir,</p>
<div class="math notranslate nohighlight">
\[H_0: \beta_7 = 0.\]</div>
<p>Entonces,</p>
<ul class="simple">
<li><p>Modelo completo:
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + \epsilon\)</span></p></li>
<li><p>Modelo nulo:
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon\)</span></p></li>
</ul>
<p>Ajustamos el modelo nulo en <code class="docutils literal notranslate"><span class="pre">Python</span></code> como <code class="docutils literal notranslate"><span class="pre">two_way_int_mod</span></code>, luego usamos <code class="docutils literal notranslate"><span class="pre">anova_lm()</span></code> para realizar una prueba <span class="math notranslate nohighlight">\(F\)</span> como de costumbre.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">two_way_int_mod</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp * hp + disp * domestic + hp * domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">two_way_int_mod</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    mpg   R-squared:                       0.759
Model:                            OLS   Adj. R-squared:                  0.755
Method:                 Least Squares   F-statistic:                     197.2
Date:                Mon, 18 Sep 2023   Prob (F-statistic):          7.68e-113
Time:                        12:47:55   Log-Likelihood:                -1059.6
No. Observations:                 383   AIC:                             2133.
Df Residuals:                     376   BIC:                             2161.
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept        52.0420      1.786     29.134      0.000      48.530      55.554
disp             -0.0627      0.025     -2.502      0.013      -0.112      -0.013
hp               -0.2519      0.029     -8.601      0.000      -0.309      -0.194
disp:hp           0.0005   7.36e-05      6.297      0.000       0.000       0.001
domestic         -3.6153      2.480     -1.458      0.146      -8.492       1.262
disp:domestic    -0.0305      0.025     -1.224      0.222      -0.079       0.018
hp:domestic       0.0784      0.037      2.115      0.035       0.006       0.151
==============================================================================
Omnibus:                       56.290   Durbin-Watson:                   1.072
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              124.316
Skew:                           0.766   Prob(JB):                     1.01e-27
Kurtosis:                       5.332   Cond. No.                     4.28e+05
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.28e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ANOVA comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">two_way_int_mod</span><span class="p">,</span> <span class="n">big_model</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid         ssr  df_diff   ss_diff         F    Pr(&gt;F)
0     376.0  5673.45199      0.0       NaN       NaN       NaN
1     375.0  5645.85155      1.0  27.60044  1.833234  0.176561
</pre></div>
</div>
</div>
</div>
<p>Vemos que el valor p es algo grande, por lo que no lo rechazaríamos. Preferimos el modelo nulo, más pequeño y menos flexible, sin la interacción de tres vías.</p>
<p>Una nota rápida aquí: el modelo completo sigue “ajustándose mejor”. Observe que tiene un RMSE menor que el modelo nulo, lo que significa que el modelo completo comete errores (al cuadrado) menores de media.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">((</span><span class="n">big_model</span><span class="o">.</span><span class="n">resid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="nb">print</span><span class="p">((</span><span class="n">two_way_int_mod</span><span class="o">.</span><span class="n">resid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14.741126762831584
14.813190574889921
</pre></div>
</div>
</div>
</div>
<p>Sin embargo, no es mucho menor. Incluso podríamos decir que la diferencia es insignificante. Esta es una idea sobre la que volveremos más adelante con más detalle.</p>
<p>Ahora que hemos elegido el modelo sin la interacción de tres vías, ¿podemos ir más allá? ¿Necesitamos las interacciones bidireccionales? Probemos</p>
<div class="math notranslate nohighlight">
\[H_0: \beta_4 = \beta_5 = \beta_6 = 0.\]</div>
<p>Recuerda que ya elegimos <span class="math notranslate nohighlight">\(\beta_7 = 0\)</span>, entonces,</p>
<ul class="simple">
<li><p>Modelo completo
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon\)</span></p></li>
<li><p>Modelo nulo
<span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon\)</span></p></li>
</ul>
<p>Ajustamos el modelo nulo en <code class="docutils literal notranslate"><span class="pre">Python</span></code> como <code class="docutils literal notranslate"><span class="pre">additive_mod</span></code>, luego usamos <code class="docutils literal notranslate"><span class="pre">anova_lm()</span></code> para</p>
<p>realizar una prueba <span class="math notranslate nohighlight">\(F\)</span> como de costumbre.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">additive_mod</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;mpg ~ disp + hp + domestic&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">autompg</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">additive_mod</span><span class="p">,</span> <span class="n">two_way_int_mod</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   df_resid          ssr  df_diff      ss_diff          F        Pr(&gt;F)
0     379.0  7369.773479      0.0          NaN        NaN           NaN
1     376.0  5673.451990      3.0  1696.321489  37.473769  3.289643e-21
</pre></div>
</div>
</div>
</div>
<p>Aquí el valor p es pequeño, por lo que rechazamos el nulo y preferimos el modelo completo (alternativo). De los modelos que hemos considerado, nuestra preferencia final es para</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \epsilon.\]</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Week_7"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="7-1-Multiple_linear_regresion.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lectura 7-1: Regresión Lineal Múltiple</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Lectura 7-2: Predictores categóricos e interacciones</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-ficticias">Variables ficticias</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#interacciones">Interacciones</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variables-categoricas">Variables categóricas</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#factores-con-mas-de-dos-niveles">Factores con más de dos niveles</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#parametrizacion">Parametrización</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#creacion-de-modelos-mas-amplios">Creación de modelos más amplios</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alejandra Tabares
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>